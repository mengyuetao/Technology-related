# ------------------- define data source ----------------------
# source alias
agent.sources = source_from_kafka  
# channels alias
agent.channels = mem_channel  
# sink alias
agent.sinks = hdfs_sink  


# define kafka source
agent.sources.source_from_kafka.type = org.apache.flume.source.kafka.KafkaSource  
agent.sources.source_from_kafka.channels = mem_channel  
agent.sources.source_from_kafka.batchSize = 5000  

# set kafka broker address  
agent.sources.source_from_kafka.kafka.bootstrap.servers = 127.0.0.1:9092

# set kafka topic
agent.sources.source_from_kafka.kafka.topics = example

# set kafka groupid
agent.sources.source_from_kafka.kafka.consumer.group.id = flume-group

# defind hdfs sink
agent.sinks.hdfs_sink.type = hdfs 

# specify the channel the sink should use  
agent.sinks.hdfs_sink.channel = mem_channel

# set store hdfs path
agent.sinks.hdfs_sink.hdfs.path = hdfs://127.0.0.1:9000/data/flume/kafka/%Y%m%d  

# set file size to trigger roll
agent.sinks.hdfs_sink.hdfs.rollSize =67108864
agent.sinks.hdfs_sink.hdfs.rollInterval = 3600  
agent.sinks.hdfs_sink.hdfs.fileType=DataStream    
agent.sinks.hdfs_sink.hdfs.writeFormat=Text 
agent.sinks.hdfs_sink.hdfs.minBlockReplicas=1

agent.sinks.hdfs_sink.hdfs.roundValue=10
agent.sinks.hdfs_sink.hdfs.roundUnit = minute

# define channel from kafka source to hdfs sink 
agent.channels.mem_channel.type = memory  

# channel store size
agent.channels.mem_channel.capacity = 100000
# transaction size
agent.channels.mem_channel.transactionCapacity = 10000
